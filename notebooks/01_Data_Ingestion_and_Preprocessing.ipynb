{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363baa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from telethon.sync import TelegramClient\n",
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "from telethon.errors.rpcerrorlist import ChannelInvalidError, ChannelPrivateError\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow running asyncio event loops within a Jupyter notebook\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbf8c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading credentials from .env file...\n",
      "Credentials loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading credentials from .env file...\")\n",
    "load_dotenv()\n",
    "\n",
    "# Get credentials securely from the environment\n",
    "api_id = os.getenv(\"API_ID\")\n",
    "api_hash = os.getenv(\"API_HASH\")\n",
    "phone = os.getenv(\"PHONE_NUMBER\")\n",
    "\n",
    "# Check if the variables were loaded correctly\n",
    "if not all([api_id, api_hash, phone]):\n",
    "    raise ValueError(\"API_ID, API_HASH, or PHONE_NUMBER not found. Make sure you have a .env file in the project root with the correct values.\")\n",
    "\n",
    "print(\"Credentials loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2754934",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "channels_to_scrape = [\n",
    "    'ZemenExpress',\n",
    "    'nevacomputer',\n",
    "    'kuruwear',\n",
    "    'helloomarketethiopia',\n",
    "    'Shewabrand'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d732a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_messages(client, channel_identifier, limit=300):\n",
    "    \"\"\"\n",
    "    Asynchronously fetches message history from a single Telegram channel using its ID or username.\n",
    "    \"\"\"\n",
    "    all_messages = []\n",
    "    channel_name_for_print = str(channel_identifier) # Default name for logging\n",
    "\n",
    "    try:\n",
    "        # This works whether you provide a username or an integer ID\n",
    "        channel_entity = await client.get_entity(channel_identifier)\n",
    "        channel_name_for_print = getattr(channel_entity, 'username', str(channel_identifier))\n",
    "        \n",
    "        async for message in client.iter_messages(channel_entity, limit=limit):\n",
    "            # We only care about messages with text content\n",
    "            if message.text:\n",
    "                all_messages.append({\n",
    "                    'channel_name': getattr(channel_entity, 'username', str(channel_identifier)),\n",
    "                    'message_id': message.id,\n",
    "                    'timestamp': message.date,\n",
    "                    'text_original': message.text,\n",
    "                    'views': message.views if message.views else 0,\n",
    "                    'has_image': message.photo is not None\n",
    "                })\n",
    "        \n",
    "        print(f\"Successfully scraped {len(all_messages)} messages from @{channel_name_for_print}.\")\n",
    "        return all_messages\n",
    "\n",
    "    except (ChannelInvalidError, ValueError):\n",
    "        print(f\"Error: Channel '@{channel_name_for_print}' not found or is invalid. Skipping.\")\n",
    "        return []\n",
    "    except ChannelPrivateError:\n",
    "        print(f\"Error: Channel '@{channel_name_for_print}' is private. You must join it first. Skipping.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred with @{channel_name_for_print}: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac91470",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"Main function to coordinate the scraping process.\"\"\"\n",
    "    all_scraped_data = []\n",
    "    \n",
    "    # The 'async with' block handles connecting and disconnecting automatically\n",
    "    # The session file will be created in the root directory.\n",
    "    async with TelegramClient('session_name', api_id, api_hash) as client:\n",
    "        print(\"Client created successfully. Starting to scrape channels...\")\n",
    "        for channel in channels_to_scrape:\n",
    "            print(f\"--- Processing channel: {channel} ---\")\n",
    "            channel_data = await fetch_messages(client, channel, limit=300) # Fetch up to 300 messages per channel\n",
    "            all_scraped_data.extend(channel_data)\n",
    "\n",
    "    if not all_scraped_data:\n",
    "        print(\"\\nScraping finished, but no data was collected. Please check your channel IDs/usernames and network.\")\n",
    "        return pd.DataFrame() # Return an empty dataframe\n",
    "    \n",
    "    df = pd.DataFrame(all_scraped_data)\n",
    "    \n",
    "    # Save the raw scraped data before any cleaning\n",
    "    df.to_csv('../data/scraped_data.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nScraping complete. Collected a total of {len(df)} messages.\")\n",
    "    print(\"Raw data saved to 'data/scraped_data.csv'\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eabdc8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the scraping process...\n",
      "Client created successfully. Starting to scrape channels...\n",
      "--- Processing channel: ZemenExpress ---\n",
      "Successfully scraped 118 messages from @ZemenExpress.\n",
      "--- Processing channel: nevacomputer ---\n",
      "Successfully scraped 92 messages from @nevacomputer.\n",
      "--- Processing channel: kuruwear ---\n",
      "Successfully scraped 164 messages from @kuruwear.\n",
      "--- Processing channel: helloomarketethiopia ---\n",
      "Successfully scraped 276 messages from @helloomarketethiopia.\n",
      "--- Processing channel: Shewabrand ---\n",
      "Successfully scraped 246 messages from @Shewabrand.\n",
      "\n",
      "Scraping complete. Collected a total of 896 messages.\n",
      "Raw data saved to 'data/scraped_data.csv'\n",
      "\n",
      "--- Starting Data Preprocessing ---\n",
      "Cleaning text data...\n",
      "Preprocessing complete. Cleaned data saved to 'data/preprocessed_data.csv'\n",
      "\n",
      "--- Preprocessed DataFrame Sample ---\n",
      "Top 5 rows:\n",
      "   channel_name                                       text_cleaned  views\n",
      "0  ZemenExpress  ................................... 3pcs Bottl...    667\n",
      "1  ZemenExpress  ................................... 3pcs Bottl...    564\n",
      "2  ZemenExpress  ................................... 1 pairs Sn...   1125\n",
      "3  ZemenExpress  ................................... 1 pairs Sn...   1102\n",
      "4  ZemenExpress  ................................... Imitation ...   2951\n",
      "\n",
      "Random 5 rows:\n",
      "     channel_name                                       text_cleaned  views\n",
      "680    Shewabrand  adidas predator accuracy ORIGINAL üíØ Size 40 MA...   8388\n",
      "810    Shewabrand  NIKE LUNAR Size41 MADE IN VIETNAM SHEWA BRAND ...  12461\n",
      "135  nevacomputer  **** üÖëÔ∏éüÖ°Ô∏éüÖêÔ∏éüÖùÔ∏éüÖìÔ∏é :** HP NOTEBOOK ** üÖìÔ∏éüÖòÔ∏éüÖ¢Ô∏éüÖüÔ∏éüÖõÔ∏éüÖê...   2149\n",
      "735    Shewabrand  NEW COTTON TISHERTS üíØ original Size M MADE IN ...   9639\n",
      "878    Shewabrand  Nike React miler 3 Size 36 MADE IN VIETNAM SHE...  16734\n",
      "\n",
      "Last 5 rows:\n",
      "    channel_name                                       text_cleaned  views\n",
      "891   Shewabrand  AIR JORDAN 1 LOW Size 36 MADE IN VIETNAM SHEWA...  20278\n",
      "892   Shewabrand  AIR JORDAN 1 RETRO Size 36 MADE IN VIETNAM SHE...  19761\n",
      "893   Shewabrand  NAKED WOLFE Size 39 MADE IN VIETNAM SHEWA BRAN...  19736\n",
      "894   Shewabrand  NIKE Blazer Mid Size 40 MADE IN VIETNAM SHEWA ...  21446\n",
      "895   Shewabrand  SKECHERS AIR -cooled Size 40 MADE IN VIETNAM S...  20946\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Run the Scraper ---\n",
    "print(\"Starting the scraping process...\")\n",
    "# Note: The first time you run this, Telethon will ask for your phone number,\n",
    "# a login code sent to your Telegram app, and possibly your 2FA password.\n",
    "df_scraped = asyncio.run(main())\n",
    "\n",
    "if not df_scraped.empty:\n",
    "    print(\"\\n--- Starting Data Preprocessing ---\")\n",
    "\n",
    "    def clean_text(text):\n",
    "        \"\"\"A function to clean Amharic text for NER.\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        # Remove URLs and Telegram links\n",
    "        text = re.sub(r'http\\S+|www\\S+|t\\.me/\\S+', '', text, flags=re.MULTILINE)\n",
    "        # Remove user mentions and hashtags\n",
    "        text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "        # Remove specific decorative characters and common emojis\n",
    "        text = re.sub(r'[üí•üìåüíµ‚úÖüëâüìçüìû‚òéÔ∏èüëá‚ú®‚úî¬Æ¬©‚Ñ¢‚ù§üî•]', '', text)\n",
    "        # Replace multiple newlines/whitespace with a single space\n",
    "        text = re.sub(r'[\\n\\r\\s]+', ' ', text).strip()\n",
    "        return text\n",
    "\n",
    "    print(\"Cleaning text data...\")\n",
    "    df_scraped['text_cleaned'] = df_scraped['text_original'].apply(clean_text)\n",
    "    \n",
    "    # Save the final preprocessed data\n",
    "    df_scraped.to_csv('../data/preprocessed_data.csv', index=False, encoding='utf-8-sig')\n",
    "    print(\"Preprocessing complete. Cleaned data saved to 'data/preprocessed_data.csv'\")\n",
    "    \n",
    "    print(\"\\n--- Preprocessed DataFrame Sample ---\")\n",
    "    # Display a sample from different parts of the dataframe to see the variety\n",
    "    print(\"Top 5 rows:\")\n",
    "    print(df_scraped[['channel_name', 'text_cleaned', 'views']].head())\n",
    "    print(\"\\nRandom 5 rows:\")\n",
    "    print(df_scraped[['channel_name', 'text_cleaned', 'views']].sample(5))\n",
    "    print(\"\\nLast 5 rows:\")\n",
    "    print(df_scraped[['channel_name', 'text_cleaned', 'views']].tail())\n",
    "else:\n",
    "    print(\"\\nSkipping preprocessing because no data was scraped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
