{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e109fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fentahun/10_acadamy/EthioMart_NER_week-4/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER pipeline loaded successfully on device: CPU\n",
      "\n",
      "Extracting entities from all posts... (This may take a few minutes depending on your hardware)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 897/897 [02:23<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "               --- FinTech Vendor Scorecard for Micro-Lending ---               \n",
      "================================================================================\n",
      "      Vendor Channel  Avg. Views/Post  Posts/Week Avg. Price (ETB)  Lending Score\n",
      "        ZemenExpress             4078       20.00           657.54           5.68\n",
      "          Shewabrand            12497        5.23            84.49           5.63\n",
      "helloomarketethiopia             3612        8.33           146.02           5.21\n",
      "            kuruwear             6037        1.30         1,431.22           4.77\n",
      "        nevacomputer             3902        1.50           190.76           4.59\n",
      "================================================================================\n",
      "\n",
      "--- Analysis ---\n",
      "The 'Lending Score' balances customer engagement (views) with business consistency (posts/week).\n",
      "Based on this analysis, 'ZemenExpress' appears to be the most promising candidate for a micro-loan.\n",
      "\n",
      "Vendor scorecard saved to '../reports/vendor_scorecard.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Task 5: FinTech Vendor Scorecard Engine\n",
    "#\n",
    "# Author: Fentahun Amare\n",
    "# Date: June 24, 2025\n",
    "#\n",
    "# Objective:\n",
    "# 1. Load the best fine-tuned NER model.\n",
    "# 2. Process all scraped messages to extract entities at scale.\n",
    "# 3. Calculate key vendor performance metrics.\n",
    "# 4. Generate a final \"Lending Score\" and present the results in a scorecard.\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# This allows pandas' `progress_apply` to show a progress bar.\n",
    "tqdm.pandas()\n",
    "\n",
    "# --- Step 1: Load Preprocessed Data and the Best NER Model ---\n",
    "data_path = '../data/preprocessed_data.csv'\n",
    "model_path = \"../saved_models/amharic-ner-afro-xlmr\"\n",
    "\n",
    "# Robustness checks\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(f\"Error: Preprocessed data not found at {data_path}. Run Notebook 01 first.\")\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Error: Saved model not found at {model_path}. Run Notebook 03 first.\")\n",
    "\n",
    "# Load data and drop rows with no text or timestamp\n",
    "df = pd.read_csv(data_path).dropna(subset=['text_cleaned', 'timestamp'])\n",
    "\n",
    "# Load the fine-tuned NER pipeline. Use GPU if available for massive speedup.\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "ner_pipeline = pipeline(\"ner\", model=model_path, aggregation_strategy=\"simple\", device=device)\n",
    "print(f\"NER pipeline loaded successfully on device: {'GPU' if device == 0 else 'CPU'}\")\n",
    "\n",
    "\n",
    "# --- Step 2: Extract Entities for All Posts ---\n",
    "def extract_entities(text):\n",
    "    \"\"\"Applies the NER pipeline to a single text entry and structures the output.\"\"\"\n",
    "    try:\n",
    "        entities = ner_pipeline(text)\n",
    "        # Initialize a dictionary to hold lists of extracted entities\n",
    "        result = {'PRODUCT': [], 'PRICE': [], 'LOC': []}\n",
    "        for entity in entities:\n",
    "            group = entity['entity_group']\n",
    "            # Only store entities we care about for the scorecard\n",
    "            if group in result:\n",
    "                result[group].append(entity['word'])\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        # If the pipeline fails on a specific text, return an empty dict\n",
    "        print(f\"Could not process text: {text[:50]}... Error: {e}\")\n",
    "        return {'PRODUCT': [], 'PRICE': [], 'LOC': []}\n",
    "\n",
    "print(\"\\nExtracting entities from all posts... (This may take a few minutes depending on your hardware)\")\n",
    "df['entities'] = df['text_cleaned'].progress_apply(extract_entities)\n",
    "\n",
    "\n",
    "# --- Step 3: Develop the Vendor Analytics Engine ---\n",
    "def clean_price(price_list):\n",
    "    \"\"\"Extracts a numerical price from a list of price entity strings.\"\"\"\n",
    "    if not price_list: return np.nan\n",
    "    # Join all parts of the price and find the first number\n",
    "    price_str = \" \".join(price_list)\n",
    "    numbers = re.findall(r'\\d[\\d,.]*', price_str)\n",
    "    if numbers:\n",
    "        # Take the first number, remove commas, and convert to float\n",
    "        return float(numbers[0].replace(',', ''))\n",
    "    return np.nan\n",
    "\n",
    "# Apply the price cleaning function to get a numeric price column\n",
    "df['price_numeric'] = df['entities'].apply(lambda x: clean_price(x.get('PRICE', [])))\n",
    "# Convert timestamp column to datetime objects for calculations\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# --- Step 4: Calculate Key Vendor Metrics and Lending Score ---\n",
    "vendor_analytics = []\n",
    "# Group the entire dataset by vendor channel\n",
    "for vendor, data in df.groupby('channel_name'):\n",
    "    \n",
    "    # 1. Activity & Consistency:\n",
    "    time_span_days = (data['timestamp'].max() - data['timestamp'].min()).days\n",
    "    # Calculate posts per week. Avoid division by zero.\n",
    "    posting_frequency = len(data) / (time_span_days / 7) if time_span_days >= 7 else len(data)\n",
    "\n",
    "    # 2. Market Reach & Engagement:\n",
    "    avg_views_per_post = data['views'].mean()\n",
    "\n",
    "    # 3. Business Profile (from NER):\n",
    "    avg_price_point = data['price_numeric'].mean() # mean() automatically ignores NaNs\n",
    "\n",
    "    # 4. Create the Final \"Lending Score\" as per the project brief:\n",
    "    # Score = (Avg Views * 0.5) + (Posting Frequency * 0.5)\n",
    "    # We use np.log1p to normalize the values and prevent extreme view counts from dominating the score.\n",
    "    # This provides a more balanced view of engagement and consistency.\n",
    "    lending_score = (np.log1p(avg_views_per_post) * 0.5) + (np.log1p(posting_frequency) * 0.5)\n",
    "    \n",
    "    vendor_analytics.append({\n",
    "        'Vendor Channel': vendor,\n",
    "        'Avg. Views/Post': int(avg_views_per_post),\n",
    "        'Posts/Week': round(posting_frequency, 2),\n",
    "        'Avg. Price (ETB)': f\"{avg_price_point:,.2f}\" if pd.notna(avg_price_point) else 'N/A',\n",
    "        'Lending Score': round(lending_score, 2),\n",
    "    })\n",
    "\n",
    "# Create the final scorecard dataframe and sort by the Lending Score\n",
    "df_scorecard = pd.DataFrame(vendor_analytics).sort_values(by=\"Lending Score\", ascending=False)\n",
    "\n",
    "# --- Step 5: Present the Final Scorecard ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"--- FinTech Vendor Scorecard for Micro-Lending ---\".center(80))\n",
    "print(\"=\"*80)\n",
    "print(df_scorecard.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n--- Analysis ---\")\n",
    "if not df_scorecard.empty:\n",
    "    top_vendor = df_scorecard.iloc[0]['Vendor Channel']\n",
    "    print(f\"The 'Lending Score' balances customer engagement (views) with business consistency (posts/week).\")\n",
    "    print(f\"Based on this analysis, '{top_vendor}' appears to be the most promising candidate for a micro-loan.\")\n",
    "else:\n",
    "    print(\"No vendor data to analyze.\")\n",
    "\n",
    "# Save the final scorecard to a CSV file for the report.\n",
    "scorecard_path = '../reports/vendor_scorecard.csv'\n",
    "df_scorecard.to_csv(scorecard_path, index=False)\n",
    "print(f\"\\nVendor scorecard saved to '{scorecard_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
